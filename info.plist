<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>bundleid</key>
	<string>ai.lemke.chatfred</string>
	<key>category</key>
	<string>Tools</string>
	<key>connections</key>
	<dict>
		<key>67B538ED-D0BA-41DC-99FF-4478B016372D</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>B3B5B552-B537-4D50-8DA3-4411C42285BC</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
		<key>7B3B0EFA-A003-4C15-9647-0F1550A51D14</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>67B538ED-D0BA-41DC-99FF-4478B016372D</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
	</dict>
	<key>createdby</key>
	<string>Chris Lemke</string>
	<key>description</key>
	<string>Alfred workflow using OpenAI's GPT model.</string>
	<key>disabled</key>
	<false/>
	<key>name</key>
	<string>ChatFred</string>
	<key>objects</key>
	<array>
		<dict>
			<key>config</key>
			<dict>
				<key>alfredfiltersresults</key>
				<false/>
				<key>alfredfiltersresultsmatchmode</key>
				<integer>0</integer>
				<key>argumenttreatemptyqueryasnil</key>
				<true/>
				<key>argumenttrimmode</key>
				<integer>0</integer>
				<key>argumenttype</key>
				<integer>0</integer>
				<key>escaping</key>
				<integer>126</integer>
				<key>keyword</key>
				<string>cf</string>
				<key>queuedelaycustom</key>
				<integer>3</integer>
				<key>queuedelayimmediatelyinitially</key>
				<false/>
				<key>queuedelaymode</key>
				<integer>2</integer>
				<key>queuemode</key>
				<integer>1</integer>
				<key>runningsubtext</key>
				<string>ChatFred is thinking ...</string>
				<key>script</key>
				<string>var='{query}'
var=${var//\?/|Q|}
var=${var//\!/|E|}
var=${var//\./|S|}

python3 main.py $var</string>
				<key>scriptargtype</key>
				<integer>0</integer>
				<key>scriptfile</key>
				<string></string>
				<key>subtext</key>
				<string></string>
				<key>title</key>
				<string>You say: '{query}'</string>
				<key>type</key>
				<integer>5</integer>
				<key>withspace</key>
				<true/>
			</dict>
			<key>type</key>
			<string>alfred.workflow.input.scriptfilter</string>
			<key>uid</key>
			<string>7B3B0EFA-A003-4C15-9647-0F1550A51D14</string>
			<key>version</key>
			<integer>3</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>autopaste</key>
				<false/>
				<key>clipboardtext</key>
				<string>{query}</string>
				<key>ignoredynamicplaceholders</key>
				<false/>
				<key>transient</key>
				<false/>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.clipboard</string>
			<key>uid</key>
			<string>67B538ED-D0BA-41DC-99FF-4478B016372D</string>
			<key>version</key>
			<integer>3</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>lastpathcomponent</key>
				<false/>
				<key>onlyshowifquerypopulated</key>
				<true/>
				<key>removeextension</key>
				<false/>
				<key>text</key>
				<string>{query}</string>
				<key>title</key>
				<string>Copied to clipboard:</string>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.notification</string>
			<key>uid</key>
			<string>B3B5B552-B537-4D50-8DA3-4411C42285BC</string>
			<key>version</key>
			<integer>1</integer>
		</dict>
	</array>
	<key>readme</key>
	<string>&lt;img src="https://raw.githubusercontent.com/chrislemke/chatfred/main/assets/images/chatfred.png" alt="ChatFred Logo" width="200" height="200"/&gt;&lt;br&gt;

# ChatFred
**[Alfred](https://www.alfredapp.com/) workflow using [OpenAI's](https://openai.com/) GPT model ðŸ¤–**

## Setup
The setup is simple. Just install the workflow and add your OpenAI API key. You can get your key [here](https://beta.openai.com/signup). Simply sign up and create an API key. Then add it to the workflow.

### Tweaking the workflow (optional)
You can tweak the workflow to your liking. The following parameters are available:
- `model`: Following models are available: `ada`, `babbage`, `curie`, `text-davinci-003` (ascending quality). Default: `text-davinci-003`.
- `temperature`: The temperature determines how greedy the generative model is. If the temperature is high, the model can output words other than the highest probability with a fairly high probability. The generated text will be more diverse, but there is a higher probability of grammar errors and the generation of nonsense. Default: `0`.
- `max_tokens`: The maximum number of tokens to generate in the completion. Default: `100`.
- `top_p`: Top-p sampling selects from the smallest possible set of words whose cumulative probability exceeds probability p. In this way, the number of words in the set can be dynamically increased and decreased according to the nearest word probability distribution. Default: `1`.
- `frequency_penalty`: A value between -2.0 and 2.0. The frequency penalty parameter controls the modelâ€™s tendency to repeat predictions. Default: `0`.
- `presence_penalty`: A Value between -2.0 and 2.0. The presence penalty parameter encourages the model to make novel predictions. Default: `0`.

 You can find more information about these parameters [here](https://platform.openai.com/docs/api-reference/completions/create).

## Usage
Just ask the model whatever you want. The model will answer to you. If you want to copy its answer, just press &lt;kbd&gt;RETURN&lt;/kbd&gt; and paste it wherever you want.

![Screenshot](https://raw.githubusercontent.com/chrislemke/ChatFred/main/assets/images/screenshot.png)

GTP-3 is a very powerful model. It can answer questions, write stories, and even write code. You can find more examples [here](https://platform.openai.com/examples).

## GPT-3 and ChatGPT
OpenAI does not provide a ChatGPT API yet. Accordingly, this workflow also runs with the GPT-3 model. As soon as OpenAI or Microsoft Azure offers a ChatGPT API, it will be integrated into this workflow.
</string>
	<key>uidata</key>
	<dict>
		<key>67B538ED-D0BA-41DC-99FF-4478B016372D</key>
		<dict>
			<key>note</key>
			<string>Copy translated text to the clipboard.</string>
			<key>xpos</key>
			<real>485.0</real>
			<key>ypos</key>
			<real>100.0</real>
		</dict>
		<key>7B3B0EFA-A003-4C15-9647-0F1550A51D14</key>
		<dict>
			<key>xpos</key>
			<real>200.0</real>
			<key>ypos</key>
			<real>55.0</real>
		</dict>
		<key>B3B5B552-B537-4D50-8DA3-4411C42285BC</key>
		<dict>
			<key>note</key>
			<string>Show a notifciation when text was copied to the clipboard.</string>
			<key>xpos</key>
			<real>400.0</real>
			<key>ypos</key>
			<real>300.0</real>
		</dict>
	</dict>
	<key>userconfigurationconfig</key>
	<array>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string></string>
				<key>placeholder</key>
				<string>sk- ...</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>Your personal API OpenAI key.</string>
			<key>label</key>
			<string>API-Key</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>api_key</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>text-davinci-003</string>
				<key>placeholder</key>
				<string>text-davinci-003</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>Following models are available: "ada", "babbage", "curie", "text-davinci-003" (ascending quality). Read more about pricing: https://openai.com/api/pricing/</string>
			<key>label</key>
			<string>OpenAI model</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>model</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>0</string>
				<key>placeholder</key>
				<string>0</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>The temperature determines how greedy the generative model is. If the temperature is high, the model can output words other than the highest probability with a fairly high probability. The generated text will be more diverse, but there is a higher probability for grammar errors and the generation of nonsense.</string>
			<key>label</key>
			<string>Temperature</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>temperature</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>100</string>
				<key>placeholder</key>
				<string>100</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>The maximum number of tokens to generate in the completion.</string>
			<key>label</key>
			<string>Maximum tokens</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>max_tokens</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>1</string>
				<key>placeholder</key>
				<string>1</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>Top-p sampling selects from the smallest possible set of words whose cumulative probability exceeds probability p. In this way, the number of words in the set can be dynamically increased and decreased according to the nearest word probability distribution.</string>
			<key>label</key>
			<string>Top-p</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>top_p</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>0.0</string>
				<key>placeholder</key>
				<string>0.0</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>A value between -2.0 and 2.0. The frequency penalty parameter controls the modelâ€™s tendency to repeat predictions.</string>
			<key>label</key>
			<string>Frequency penalty</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>frequency_penalty</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>0.0</string>
				<key>placeholder</key>
				<string>0.0</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>A Value between -2.0 and 2.0. The presence penalty parameter encourages the model to make novel predictions.</string>
			<key>label</key>
			<string>Presence penalty</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>presence_penalty</string>
		</dict>
	</array>
	<key>version</key>
	<string>0.1.0</string>
	<key>webaddress</key>
	<string>https://github.com/chrislemke/ChatFred</string>
</dict>
</plist>
