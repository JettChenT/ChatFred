<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>bundleid</key>
	<string>ai.lemke.chatfred</string>
	<key>connections</key>
	<dict>
		<key>00A84B22-93A9-4F5B-8208-5A09AE39A270</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>7B3B0EFA-A003-4C15-9647-0F1550A51D14</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
		<key>3BF9843F-60FD-4683-9ADF-C5533691858B</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>C7A6C68C-D4BD-4E85-9A6B-D1255B3136BA</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
		<key>51EEBBF2-BE53-4A88-965F-02AC2D651EF5</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>547CA7CA-D433-488C-9950-FF584AE9601E</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>sourceoutputuid</key>
				<string>A851B8B3-DE1D-4DE3-B4F8-F65F92241CDC</string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
		<key>547CA7CA-D433-488C-9950-FF584AE9601E</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>F0B1523D-0C58-4D43-9BC2-C96560E8AD95</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
		<key>5D9861D9-2F55-408C-B1BD-33ADD7A02566</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>3BF9843F-60FD-4683-9ADF-C5533691858B</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
		<key>7B3B0EFA-A003-4C15-9647-0F1550A51D14</key>
		<array>
			<dict>
				<key>destinationuid</key>
				<string>AD7BB662-4857-404A-9CEC-3F8D966EEF52</string>
				<key>modifiers</key>
				<integer>524288</integer>
				<key>modifiersubtext</key>
				<string>Let ChatFred speak</string>
				<key>vitoclose</key>
				<true/>
			</dict>
			<dict>
				<key>destinationuid</key>
				<string>AD46F538-F4DD-41B2-BE43-E830535CA0E3</string>
				<key>modifiers</key>
				<integer>1048576</integer>
				<key>modifiersubtext</key>
				<string>Show repy in large text</string>
				<key>vitoclose</key>
				<false/>
			</dict>
			<dict>
				<key>destinationuid</key>
				<string>547CA7CA-D433-488C-9950-FF584AE9601E</string>
				<key>modifiers</key>
				<integer>131072</integer>
				<key>modifiersubtext</key>
				<string>Save conversation to file</string>
				<key>vitoclose</key>
				<false/>
			</dict>
			<dict>
				<key>destinationuid</key>
				<string>51EEBBF2-BE53-4A88-965F-02AC2D651EF5</string>
				<key>modifiers</key>
				<integer>0</integer>
				<key>modifiersubtext</key>
				<string></string>
				<key>vitoclose</key>
				<false/>
			</dict>
			<dict>
				<key>destinationuid</key>
				<string>3BF9843F-60FD-4683-9ADF-C5533691858B</string>
				<key>modifiers</key>
				<integer>262144</integer>
				<key>modifiersubtext</key>
				<string>Copy reply to clipboard</string>
				<key>vitoclose</key>
				<false/>
			</dict>
			<dict>
				<key>destinationuid</key>
				<string>5D9861D9-2F55-408C-B1BD-33ADD7A02566</string>
				<key>modifiers</key>
				<integer>1310720</integer>
				<key>modifiersubtext</key>
				<string>Show repy in large text and copy to clipboard</string>
				<key>vitoclose</key>
				<false/>
			</dict>
		</array>
		<key>AD46F538-F4DD-41B2-BE43-E830535CA0E3</key>
		<array/>
	</dict>
	<key>createdby</key>
	<string>Chris Lemke</string>
	<key>description</key>
	<string>Alfred workflow using OpenAI's model for chatting, etc.</string>
	<key>disabled</key>
	<false/>
	<key>name</key>
	<string>ChatFred</string>
	<key>objects</key>
	<array>
		<dict>
			<key>config</key>
			<dict>
				<key>text</key>
				<string>{query}</string>
				<key>usevoiceover</key>
				<true/>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.speak</string>
			<key>uid</key>
			<string>AD7BB662-4857-404A-9CEC-3F8D966EEF52</string>
			<key>version</key>
			<integer>1</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>alignment</key>
				<integer>0</integer>
				<key>backgroundcolor</key>
				<string></string>
				<key>fadespeed</key>
				<integer>50</integer>
				<key>fillmode</key>
				<integer>0</integer>
				<key>font</key>
				<string></string>
				<key>ignoredynamicplaceholders</key>
				<false/>
				<key>largetypetext</key>
				<string>{query}</string>
				<key>textcolor</key>
				<string></string>
				<key>wrapat</key>
				<integer>100</integer>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.largetype</string>
			<key>uid</key>
			<string>AD46F538-F4DD-41B2-BE43-E830535CA0E3</string>
			<key>version</key>
			<integer>3</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>lastpathcomponent</key>
				<false/>
				<key>onlyshowifquerypopulated</key>
				<true/>
				<key>removeextension</key>
				<false/>
				<key>text</key>
				<string>Reply saved to file</string>
				<key>title</key>
				<string>ChatFred</string>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.notification</string>
			<key>uid</key>
			<string>F0B1523D-0C58-4D43-9BC2-C96560E8AD95</string>
			<key>version</key>
			<integer>1</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>adduuid</key>
				<false/>
				<key>allowemptyfiles</key>
				<false/>
				<key>createintermediatefolders</key>
				<false/>
				<key>filename</key>
				<string>{var:save_to_file_dir}/ChatFred.txt</string>
				<key>filetext</key>
				<string>{date}, {time}:
Request:
 {var:request}

Reply: 
{query}
---
</string>
				<key>ignoredynamicplaceholders</key>
				<false/>
				<key>relativepathmode</key>
				<integer>0</integer>
				<key>type</key>
				<integer>2</integer>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.writefile</string>
			<key>uid</key>
			<string>547CA7CA-D433-488C-9950-FF584AE9601E</string>
			<key>version</key>
			<integer>1</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>action</key>
				<integer>0</integer>
				<key>argument</key>
				<integer>0</integer>
				<key>focusedappvariable</key>
				<false/>
				<key>focusedappvariablename</key>
				<string></string>
				<key>hotkey</key>
				<integer>0</integer>
				<key>hotmod</key>
				<integer>0</integer>
				<key>leftcursor</key>
				<false/>
				<key>modsmode</key>
				<integer>0</integer>
				<key>relatedAppsMode</key>
				<integer>0</integer>
			</dict>
			<key>type</key>
			<string>alfred.workflow.trigger.hotkey</string>
			<key>uid</key>
			<string>00A84B22-93A9-4F5B-8208-5A09AE39A270</string>
			<key>version</key>
			<integer>2</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>alfredfiltersresults</key>
				<false/>
				<key>alfredfiltersresultsmatchmode</key>
				<integer>0</integer>
				<key>argumenttreatemptyqueryasnil</key>
				<true/>
				<key>argumenttrimmode</key>
				<integer>0</integer>
				<key>argumenttype</key>
				<integer>0</integer>
				<key>escaping</key>
				<integer>126</integer>
				<key>keyword</key>
				<string>cf</string>
				<key>queuedelaycustom</key>
				<integer>3</integer>
				<key>queuedelayimmediatelyinitially</key>
				<false/>
				<key>queuedelaymode</key>
				<integer>2</integer>
				<key>queuemode</key>
				<integer>1</integer>
				<key>runningsubtext</key>
				<string>ChatFred is thinking ...</string>
				<key>script</key>
				<string>python3 src/main.py $1</string>
				<key>scriptargtype</key>
				<integer>1</integer>
				<key>scriptfile</key>
				<string></string>
				<key>subtext</key>
				<string>Talking to GPT models</string>
				<key>title</key>
				<string>ChatFred</string>
				<key>type</key>
				<integer>5</integer>
				<key>withspace</key>
				<true/>
			</dict>
			<key>type</key>
			<string>alfred.workflow.input.scriptfilter</string>
			<key>uid</key>
			<string>7B3B0EFA-A003-4C15-9647-0F1550A51D14</string>
			<key>version</key>
			<integer>3</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>conditions</key>
				<array>
					<dict>
						<key>inputstring</key>
						<string>{var:save_to_file}</string>
						<key>matchcasesensitive</key>
						<true/>
						<key>matchmode</key>
						<integer>5</integer>
						<key>matchstring</key>
						<string>0</string>
						<key>outputlabel</key>
						<string>{query}</string>
						<key>uid</key>
						<string>A851B8B3-DE1D-4DE3-B4F8-F65F92241CDC</string>
					</dict>
				</array>
				<key>elselabel</key>
				<string>else</string>
				<key>hideelse</key>
				<true/>
			</dict>
			<key>type</key>
			<string>alfred.workflow.utility.conditional</string>
			<key>uid</key>
			<string>51EEBBF2-BE53-4A88-965F-02AC2D651EF5</string>
			<key>version</key>
			<integer>1</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>autopaste</key>
				<false/>
				<key>clipboardtext</key>
				<string>{query}</string>
				<key>ignoredynamicplaceholders</key>
				<false/>
				<key>transient</key>
				<false/>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.clipboard</string>
			<key>uid</key>
			<string>3BF9843F-60FD-4683-9ADF-C5533691858B</string>
			<key>version</key>
			<integer>3</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>lastpathcomponent</key>
				<false/>
				<key>onlyshowifquerypopulated</key>
				<true/>
				<key>removeextension</key>
				<false/>
				<key>text</key>
				<string>Reply copied to clipboard</string>
				<key>title</key>
				<string>ChatFred</string>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.notification</string>
			<key>uid</key>
			<string>C7A6C68C-D4BD-4E85-9A6B-D1255B3136BA</string>
			<key>version</key>
			<integer>1</integer>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>alignment</key>
				<integer>0</integer>
				<key>backgroundcolor</key>
				<string></string>
				<key>fadespeed</key>
				<integer>50</integer>
				<key>fillmode</key>
				<integer>0</integer>
				<key>font</key>
				<string></string>
				<key>ignoredynamicplaceholders</key>
				<false/>
				<key>largetypetext</key>
				<string>{query}</string>
				<key>textcolor</key>
				<string></string>
				<key>wrapat</key>
				<integer>100</integer>
			</dict>
			<key>type</key>
			<string>alfred.workflow.output.largetype</string>
			<key>uid</key>
			<string>5D9861D9-2F55-408C-B1BD-33ADD7A02566</string>
			<key>version</key>
			<integer>3</integer>
		</dict>
	</array>
	<key>readme</key>
	<string>![chatfred](assets/images/chatfred.png)

# ChatFred
**[Alfred](https://www.alfredapp.com/) workflow using [OpenAI's](https://openai.com/) GPT model for chatting, text completion and much more 🤖**

## Setup 🛠️
The setup is simple. Just install the workflow and add your OpenAI API key. You can get your key [here](https://beta.openai.com/signup) - You will receive $18 in free credit, no payment data is required and you can start talking to ChatFred right away.

### Tweaking the workflow (optional) 🦾
You can tweak the workflow to your liking. The following parameters are available:
- **OpenAI model**: Following models are available: `Ada`, `Babbage`, `Curie`, `Davinci` (ascending quality). Default: `Davinci`.
- **Temperature**: The temperature determines how greedy the generative model is. If the temperature is high, the model can output words other than the highest probability with a fairly high probability. The generated text will be more diverse, but there is a higher probability of grammar errors and the generation of nonsense. Default: `0`.
- **Maximum tokens**: The maximum number of tokens to generate in the completion. Default: `100`.
- **Top-p**: Top-p sampling selects from the smallest possible set of words whose cumulative probability exceeds probability p. In this way, the number of words in the set can be dynamically increased and decreased according to the nearest word probability distribution. Default: `1`.
- **Frequency penalty**: A value between -2.0 and 2.0. The frequency penalty parameter controls the model’s tendency to repeat predictions. Default: `0`.
- **Presence penalty**: A Value between -2.0 and 2.0. The presence penalty parameter encourages the model to make novel predictions. Default: `0`.
- **Always save conversation**: If enabled, all your request and ChatFred's replies will be saved to a file (`{Save to file directory}/ChatFred.txt`). Default: 'unchecked'.
- **Save to file directory**: Custom directory where the 'ChatFred.txt' should be stored. Default to the user's home directory (`~/`).

You can find more information about the model's parameters [here](https://platform.openai.com/docs/api-reference/completions/create).

## Usage 🧑‍💻
To start the ChatFred workflow, just type ***cf*** or use configure your own hotkey.

Ask questions:
![Screenshot](assets/images/screenshot1.png)

Translate text:
![Screenshot](assets/images/screenshot2.png)

If the reply is a bit longer just hit &lt;kbd&gt;CMD ⌘&lt;/kbd&gt; + &lt;kbd&gt;RETURN ⏎&lt;/kbd&gt;:
![Screenshot](assets/images/screenshot3.png)
![Screenshot](assets/images/screenshot4.png)

### Options 🤗
To handle the reply of ChatFred you have the following options.
- &lt;kbd&gt;CMD ⌘&lt;/kbd&gt;: Show the reply in large text (can be combined with &lt;kbd&gt;CTRL ⌃&lt;/kbd&gt;)
- &lt;kbd&gt;OPTION ⌥&lt;/kbd&gt;: Let ChatFred speak 🗣️
- &lt;kbd&gt;CTRL ⌃&lt;/kbd&gt;: Copy the reply to the clipboard
- &lt;kbd&gt;SHIFT ⇧&lt;/kbd&gt;: Write the conversation to file: `ChatFred.txt`. The default location is the user's home directory (`~/`). You can change the location in the workflow configuration.

### Save conversations to file 📝
If you want to save all requests and ChatFred's replies to a file, you can enable this option in the workflow configuration (*Save to file directory*). The default location is the user's home directory (`~/`).

You can also hit &lt;kbd&gt;SHIFT ⇧&lt;/kbd&gt; + &lt;kbd&gt;RETURN ⏎&lt;/kbd&gt; for saving the reply manually.

### Examples 📚
GTP-3 is a very powerful model. It can answer questions, write stories, and even write code. You can find more examples [here](https://platform.openai.com/examples).

## GPT-3 and ChatGPT 🤖
OpenAI does not provide a ChatGPT API yet. Accordingly, this workflow also runs with the GPT-3 model. As soon as OpenAI or Microsoft Azure offers a ChatGPT API, it will be integrated into this workflow.

## What's next? 🚧
As soon as OpenAI releases a ChatGPT API, I will integrate it into this workflow.</string>
	<key>uidata</key>
	<dict>
		<key>00A84B22-93A9-4F5B-8208-5A09AE39A270</key>
		<dict>
			<key>xpos</key>
			<real>30</real>
			<key>ypos</key>
			<real>285</real>
		</dict>
		<key>3BF9843F-60FD-4683-9ADF-C5533691858B</key>
		<dict>
			<key>note</key>
			<string>Copy translated text to the clipboard.</string>
			<key>xpos</key>
			<real>650</real>
			<key>ypos</key>
			<real>440</real>
		</dict>
		<key>51EEBBF2-BE53-4A88-965F-02AC2D651EF5</key>
		<dict>
			<key>xpos</key>
			<real>540</real>
			<key>ypos</key>
			<real>335</real>
		</dict>
		<key>547CA7CA-D433-488C-9950-FF584AE9601E</key>
		<dict>
			<key>xpos</key>
			<real>705</real>
			<key>ypos</key>
			<real>230</real>
		</dict>
		<key>5D9861D9-2F55-408C-B1BD-33ADD7A02566</key>
		<dict>
			<key>xpos</key>
			<real>385</real>
			<key>ypos</key>
			<real>555</real>
		</dict>
		<key>7B3B0EFA-A003-4C15-9647-0F1550A51D14</key>
		<dict>
			<key>xpos</key>
			<real>175</real>
			<key>ypos</key>
			<real>285</real>
		</dict>
		<key>AD46F538-F4DD-41B2-BE43-E830535CA0E3</key>
		<dict>
			<key>xpos</key>
			<real>705</real>
			<key>ypos</key>
			<real>45</real>
		</dict>
		<key>AD7BB662-4857-404A-9CEC-3F8D966EEF52</key>
		<dict>
			<key>xpos</key>
			<real>365</real>
			<key>ypos</key>
			<real>25</real>
		</dict>
		<key>C7A6C68C-D4BD-4E85-9A6B-D1255B3136BA</key>
		<dict>
			<key>xpos</key>
			<real>850</real>
			<key>ypos</key>
			<real>440</real>
		</dict>
		<key>F0B1523D-0C58-4D43-9BC2-C96560E8AD95</key>
		<dict>
			<key>xpos</key>
			<real>900</real>
			<key>ypos</key>
			<real>230</real>
		</dict>
	</dict>
	<key>userconfigurationconfig</key>
	<array>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string></string>
				<key>placeholder</key>
				<string>sk-...</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>Your personal API OpenAI key. Should start with: 'sk-'.</string>
			<key>label</key>
			<string>API-Key</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>api_key</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>text-davinci-003</string>
				<key>pairs</key>
				<array>
					<array>
						<string>Ada</string>
						<string>text-ada-001</string>
					</array>
					<array>
						<string>Babbage</string>
						<string>text-babbage-001</string>
					</array>
					<array>
						<string>Curie</string>
						<string>text-curie-001</string>
					</array>
					<array>
						<string>Davinci</string>
						<string>text-davinci-003</string>
					</array>
				</array>
			</dict>
			<key>description</key>
			<string>Language model used for prediction. Read more about the models: https://platform.openai.com/docs/models/gpt-3</string>
			<key>label</key>
			<string>OpenAI model</string>
			<key>type</key>
			<string>popupbutton</string>
			<key>variable</key>
			<string>model</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>0</string>
				<key>placeholder</key>
				<string>0</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>The temperature determines how greedy the generative model is. If the temperature is high, the model can output words other than the highest probability with a fairly high probability. The generated text will be more diverse, but there is a higher probability for grammar errors and the generation of nonsense.</string>
			<key>label</key>
			<string>Temperature</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>temperature</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>50</string>
				<key>placeholder</key>
				<string>50</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>The maximum number of tokens to generate in the completion.</string>
			<key>label</key>
			<string>Maximum tokens</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>max_tokens</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>1</string>
				<key>placeholder</key>
				<string>1</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>Top-p sampling selects from the smallest possible set of words whose cumulative probability exceeds probability p. In this way, the number of words in the set can be dynamically increased and decreased according to the nearest word probability distribution.</string>
			<key>label</key>
			<string>Top-p</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>top_p</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>0.0</string>
				<key>placeholder</key>
				<string>0.0</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>A value between -2.0 and 2.0. The frequency penalty parameter controls the model’s tendency to repeat predictions.</string>
			<key>label</key>
			<string>Frequency penalty</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>frequency_penalty</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>0.0</string>
				<key>placeholder</key>
				<string>0.0</string>
				<key>required</key>
				<true/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>A Value between -2.0 and 2.0. The presence penalty parameter encourages the model to make novel predictions.</string>
			<key>label</key>
			<string>Presence penalty</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>presence_penalty</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<false/>
				<key>required</key>
				<false/>
				<key>text</key>
				<string></string>
			</dict>
			<key>description</key>
			<string>Your conversation with ChatFred can be saved to file (~/ChatFred.txt) by hitting 'SHIFT+RETURN'. If this box is checked all requests and replies will be stored to file automatically.</string>
			<key>label</key>
			<string>Always save conversation</string>
			<key>type</key>
			<string>checkbox</string>
			<key>variable</key>
			<string>save_to_file</string>
		</dict>
		<dict>
			<key>config</key>
			<dict>
				<key>default</key>
				<string>~</string>
				<key>placeholder</key>
				<string>~</string>
				<key>required</key>
				<false/>
				<key>trim</key>
				<true/>
			</dict>
			<key>description</key>
			<string>Custom directory where the 'ChatFred.txt' should be stored.</string>
			<key>label</key>
			<string>Save to file directory</string>
			<key>type</key>
			<string>textfield</string>
			<key>variable</key>
			<string>save_to_file_dir</string>
		</dict>
	</array>
	<key>version</key>
	<string>0.2.2</string>
	<key>webaddress</key>
	<string>https://github.com/chrislemke/ChatFred</string>
</dict>
</plist>
